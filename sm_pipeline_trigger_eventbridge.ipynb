{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Region, session, and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = os.environ[\"AWS_REGION\"]\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "# sagemaker_boto_client = boto_session.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "account_id = boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "\n",
    "# Get the AWS EventBridge client\n",
    "event_bridge_client = boto3.client('events')\n",
    "lambda_client = boto3.client('lambda')\n",
    "event_bridge_scheduler = boto3.client(\"scheduler\")\n",
    "\n",
    "sns_client = boto3.client('sns')\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "sagemaker_session = sagemaker.Session(\n",
    "    boto_session=boto_session, sagemaker_client=sm_client\n",
    ")\n",
    "\n",
    "sm_role = get_execution_role(sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "bucket = \"artwork-content-trial-bucket\"\n",
    "prefix=\"mch-artwork-content\"\n",
    "train_data_dir_prefix=\"data\"\n",
    "pipeline_dir_prefix=\"pipeline-data\"\n",
    "# training_input_prefix = \"content_ovr_anonymised.csv\"\n",
    "training_input_prefix = \"ovr_content_data\"\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"Approved\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduling Pipeline using EventBridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_permissions(lambda_client, lambda_function_name, src_arn, account_id, prefix):\n",
    "    try :\n",
    "        response = lambda_client.add_permission(\n",
    "            FunctionName=lambda_function_name,\n",
    "            StatementId=f\"{prefix}-Trigger-Lambda-{int(time.time())}\",\n",
    "            Action='lambda:InvokeFunction',\n",
    "            Principal= f\"{prefix}.amazonaws.com\",\n",
    "            SourceArn=src_arn,\n",
    "            SourceAccount=account_id\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while adding permissions: {e}\")\n",
    "        \n",
    "    return response    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_bucket_notification(s3_client, bucket, lambda_arn, prefix):\n",
    "    try:\n",
    "        # Create the S3 bucket event notification configuration\n",
    "        response = s3_client.put_bucket_notification_configuration(\n",
    "            Bucket=bucket,\n",
    "            NotificationConfiguration={\n",
    "                \"LambdaFunctionConfigurations\": [\n",
    "                    {\n",
    "                        \"LambdaFunctionArn\": lambda_arn,\n",
    "                        \"Events\": [\n",
    "                            \"s3:ObjectCreated:Put\"\n",
    "#                             's3:ObjectCreated:CompleteMultipartUpload'\n",
    "                        ],\n",
    "                        \"Filter\": {\n",
    "                            \"Key\": {\n",
    "                                \"FilterRules\": [\n",
    "                                    {\n",
    "                                            'Name': 'suffix',\n",
    "                                            'Value': '.csv'\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"Name\": \"prefix\",\n",
    "                                        \"Value\": prefix\n",
    "                                    }\n",
    "                                ]\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while adding permissions: {e}\")\n",
    "        \n",
    "    return response        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule_pipeline(region, account_id, bucket, prefix, s3_client, event_bridge_client, lambda_client, lambda_function_name, lambda_arn):\n",
    "    \n",
    "    bucket_arn = f\"arn:aws:s3:::{bucket}\"\n",
    "\n",
    "    # Define the schedule name and expression for 20 minute intervals\n",
    "#     schedule_name= 'SMLambdaEventSchedule'\n",
    "#     schedule_expression = 'cron(0/20 * * * ? *)'\n",
    "\n",
    "    # Define the EventBridge rule name and description\n",
    "    rule_name = 'SMLambdaEventRuleTrigger'\n",
    "    rule_description = 'Event to trigger SageMaker Content pipeline via Lambda function when new data is added to S3.'\n",
    "    \n",
    "    # Define the Event Pattern\n",
    "    event_pattern = {\n",
    "            \"source\": [\n",
    "                \"aws.s3\"\n",
    "            ],\n",
    "            \"detail-type\": [\n",
    "                \"AWS API Call via CloudTrail\"\n",
    "            ],\n",
    "            \"detail\": {\n",
    "                \"eventSource\": [\n",
    "                    \"s3.amazonaws.com\"\n",
    "                ],\n",
    "                \"eventName\": [\n",
    "                    \"PutObject\"\n",
    "                ],\n",
    "                \"requestParameters\": {\n",
    "                    \"bucketName\": [\n",
    "                        bucket\n",
    "                    ],\n",
    "                    \"key\": [\n",
    "                        prefix + \"/\" + \"*\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "    # Put the EventBridge rule\n",
    "    rule_response = event_bridge_client.put_rule(\n",
    "        Name=rule_name,\n",
    "        # ScheduleExpression=schedule_expression,\n",
    "        Description=rule_description,\n",
    "        EventPattern=json.dumps(event_pattern),\n",
    "        State='ENABLED'\n",
    "    )\n",
    "    \n",
    "    event_rule_arn = rule_response['RuleArn']\n",
    "    \n",
    "    # add permissions to S3, Events\n",
    "    add_permissions(lambda_client, lambda_function_name, event_rule_arn, account_id, prefix='events')\n",
    "    add_permissions(lambda_client, lambda_function_name, bucket_arn, account_id, prefix='s3')\n",
    "    \n",
    "    \n",
    "    # set up s3 bucket notifcations\n",
    "    s3_bucket_notification(s3_client, bucket, lambda_arn, prefix)  \n",
    "   \n",
    "    \n",
    "    # Define the EventBridge target\n",
    "    target = {\n",
    "                'Arn': lambda_arn, # Replace with the actual lambda ARN\n",
    "                'Id': 'SMLambdaFunctionTarget',\n",
    "                # 'RoleArn': role['arn'], # used in case of pipeline target\n",
    "            }\n",
    "\n",
    "    # Add the target to the EventBridge rule\n",
    "    event_bridge_client.put_targets(\n",
    "        Rule=rule_name,\n",
    "        Targets=[target]\n",
    "    )\n",
    "\n",
    "    # Wait for the target to become active\n",
    "    while True:\n",
    "        response_rule = event_bridge_client.describe_rule(Name=rule_name)\n",
    "        # response_rule = event_bridge_scheduler.get_schedule(Name=schedule_name)\n",
    "\n",
    "        if response_rule['State'] == 'ENABLED':\n",
    "            print('\\n === Event Scheduled Successfully ===== \\n')\n",
    "            break\n",
    "        else:\n",
    "            print(f'response rule: {response_rule}')\n",
    "        time.sleep(5)\n",
    "\n",
    "    # Check the target status\n",
    "    response = event_bridge_client.list_targets_by_rule(Rule=rule_name)\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " === Event Scheduled Successfully ===== \n",
      "\n",
      "{'Targets': [{'Id': 'SMLambdaFunctionTarget', 'Arn': 'arn:aws:lambda:us-east-1:791574662255:function:sm-lambda-evt-trigger-fcn'}], 'ResponseMetadata': {'RequestId': 'ca4aa555-6f2a-4920-a2db-cf67efe47787', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'ca4aa555-6f2a-4920-a2db-cf67efe47787', 'content-type': 'application/x-amz-json-1.1', 'content-length': '126', 'date': 'Thu, 09 Feb 2023 16:28:20 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "pipeline_name = \"artwork-content-pipeline-demo\"\n",
    "fcn_name=\"sm-lambda-evt-trigger-fcn\"\n",
    "lambda_arn=\"arn:aws:lambda:us-east-1:791574662255:function:sm-lambda-evt-trigger-fcn\"\n",
    "\n",
    "response = schedule_pipeline(region, account_id, bucket, train_data_dir_prefix, s3_client, event_bridge_client, lambda_client, fcn_name, lambda_arn)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_name = 'SMLambdaEventRuleTrigger'\n",
    "event_bridge_client.describe_rule(Name=rule_name)\n",
    "event_bridge_client.list_targets_by_rule(Rule=rule_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_name = 'SMLambdaEventRuleTrigger'\n",
    "target_id = 'SMLambdaFunctionTarget'\n",
    "\n",
    "def stop_scheduled_event(event_bridge_client, rule_name, target_id):\n",
    "\n",
    "    # Disable the EventBridge rule\n",
    "    event_bridge_client.disable_rule(Name=rule_name)\n",
    "\n",
    "    # Remove the target for the EventBridge rule\n",
    "    event_bridge_client.remove_targets(Rule=rule_name, Ids=[target_id])\n",
    "\n",
    "# =============================================================================\n",
    "# stop_scheduled_event(event_bridge_client, rule_name, target_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps related to lambda function and role creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_utils import *\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_name = \"artwork-content-pipeline-demo\"\n",
    "# lambda_code = create_lambda_fcn(pipeline_name)\n",
    "# print(lambda_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IAM role for Lambda function\n",
    "\n",
    "role_name = f\"sm-lambda-evt-trigger-role\" #-{time.strftime('%d-%H-%M-%S', time.gmtime())}\"\n",
    "fcn_name = f\"sm-lambda-evt-trigger-fcn\" #-{time.strftime('%d-%H-%M-%S', time.gmtime())}\"\n",
    "\n",
    "#Create IAM role for the Lambda function\n",
    "# lambda_role = create_role(role_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arn': 'arn:aws:iam::791574662255:role/sm-lambda-evt-trigger-role'}\n"
     ]
    }
   ],
   "source": [
    "lambda_role = {'arn': 'arn:aws:iam::791574662255:role/sm-lambda-evt-trigger-role'}\n",
    "print(lambda_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating AWS Lambda function ...\n",
      "SUCCESS: Successfully created AWS Lambda function!\n"
     ]
    }
   ],
   "source": [
    "#Zip AWS Lambda function code\n",
    "#Write code to a .py file\n",
    "# with open('lambda_function.py', 'w') as f:\n",
    "#     f.write(inspect.cleandoc(lambda_code))\n",
    "\n",
    "\n",
    "lambda_output_path = 'lambda_output'\n",
    "os.makedirs(name=lambda_output_path, exist_ok=True)\n",
    "\n",
    "zip_path = os.path.join(lambda_output_path, 'function.zip')\n",
    "\n",
    "#Compress file into a zip\n",
    "with ZipFile(zip_path,'w') as z:\n",
    "    z.write('lambda_function.py')\n",
    "\n",
    "#Use zipped code as AWS Lambda function code\n",
    "with open(zip_path, 'rb') as f:\n",
    "    fcn_code = f.read()\n",
    "\n",
    "shutil.rmtree(lambda_output_path)\n",
    "\n",
    "#Create AWS Lambda function\n",
    "lambda_arn = create_lambda(fcn_name, fcn_code, lambda_role['arn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:lambda:us-east-1:791574662255:function:sm-lambda-evt-trigger-fcn\n"
     ]
    }
   ],
   "source": [
    "print(lambda_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create and attach trigger for Amazon S3 event to kick-off AWS Lambda function\n",
    "# print(f'Data landing zone prefix for S3 trigger: {train_data_dir_prefix}')\n",
    "# create_s3_trigger(fcn_name, bucket, train_data_dir_prefix, account_id, lambda_arn)\n",
    "\n",
    "# #Wait for the trigger to be created\n",
    "# print('Waiting for 5 seconds for the newly created trigger to be active.')\n",
    "# time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains a small sample of ovr data\n",
    "sagemaker.s3.S3Uploader.upload(\"./data/ovr_content_data_v3.csv\", \n",
    "                               f\"s3://{bucket}/{train_data_dir_prefix}\")\n",
    "#wait for file to finish uploading \n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
