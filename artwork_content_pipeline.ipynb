{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.inputs import TrainingInput, CreateModelInput\n",
    "from sagemaker.workflow.steps import TrainingStep, CreateModelStep, ProcessingStep, TransformStep\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingOutput, ProcessingInput\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Region, session, and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = os.environ[\"AWS_REGION\"]\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "# sagemaker_boto_client = boto_session.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "account_id = boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "\n",
    "# Get the AWS EventBridge client\n",
    "event_bridge_client = boto3.client('events')\n",
    "lambda_client = boto3.client('lambda')\n",
    "event_bridge_scheduler = boto3.client(\"scheduler\")\n",
    "\n",
    "sns_client = boto3.client('sns')\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "sagemaker_session = sagemaker.Session(\n",
    "    boto_session=boto_session, sagemaker_client=sm_client\n",
    ")\n",
    "\n",
    "sm_role = get_execution_role(sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "bucket = \"artwork-content-trial-bucket\"\n",
    "prefix=\"mch-artwork-content\"\n",
    "train_data_dir_prefix=\"data\"\n",
    "pipeline_dir_prefix=\"pipeline-data\"\n",
    "training_input_prefix = \"ovr_content_data\"\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"Approved\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latest ovr data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the bucket is empty\n",
    "def get_latest_ovr_content_data(s3_client, bucket, train_data_dir_prefix, training_input_prefix):\n",
    "    try:\n",
    "        content_data_path = train_data_dir_prefix+'/'+training_input_prefix\n",
    "\n",
    "        result = s3_client.list_objects(Bucket=bucket, Prefix=content_data_path)\n",
    "\n",
    "        if 'Contents' not in result.keys():\n",
    "            print(f\"There seems to be no data in the {train_data_dir_prefix}/ folder of {bucket}\")\n",
    "        else:\n",
    "            # Get the list of all objects in the bucket\n",
    "            objects = result['Contents']\n",
    "\n",
    "            # Sort the objects by LastModified\n",
    "            sorted_objects = sorted(objects, key=lambda x: x['LastModified'], reverse=True)\n",
    "\n",
    "            # Get the latest modified object\n",
    "            latest_modified_object = sorted_objects[0]\n",
    "\n",
    "            # Get the key (file name) and the last modified date of the latest modified object\n",
    "            latest_modified_content_data_key = latest_modified_object['Key']\n",
    "            latest_modified_date = latest_modified_object['LastModified']\n",
    "\n",
    "            print(\"The latest modified object is:\", latest_modified_content_data_key)\n",
    "            print(\"The last modified date is:\", latest_modified_date)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred while fetching latest ovr data. Error - {e}\")\n",
    "        \n",
    "    return latest_modified_content_data_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the data bucket is empty\n",
    "# result = s3_client.list_objects(Bucket=bucket, Prefix=content_data_path)\n",
    "\n",
    "# if 'Contents' in result.keys():\n",
    "#     print('Yes')\n",
    "# else:\n",
    "#     print('No data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_data_path = train_data_dir_prefix+'/'+training_input_prefix\n",
    "# s3_data_result = sagemaker_session.list_s3_files(bucket=bucket, key_prefix=content_data_path)\n",
    "\n",
    "# s3_data_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest modified object is: data/ovr_content_data_v3.csv\n",
      "The last modified date is: 2023-02-09 13:23:17+00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data/ovr_content_data_v3.csv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_ovr_data = get_latest_ovr_content_data(s3_client, bucket, train_data_dir_prefix, training_input_prefix)\n",
    "\n",
    "current_ovr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Estimator for training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_uri = '791574662255.dkr.ecr.us-east-1.amazonaws.com/artwork-content-train-repo:latest'\n",
    "estimator_output_path = f\"s3://{bucket}/{pipeline_dir_prefix}/\"\n",
    "training_input = f\"s3://{bucket}/{current_ovr_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_estimator = Estimator(\n",
    "    image_uri=train_image_uri,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    output_path=estimator_output_path,\n",
    "    role=sm_role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_train = TrainingStep(\n",
    "    name=\"TrainingStep\",\n",
    "    estimator=content_estimator,\n",
    "    inputs=training_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_name=\"artwork-content-model\"\n",
    "\n",
    "model = Model(\n",
    "    name=mdl_name,\n",
    "    image_uri=content_estimator.training_image_uri(),\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=sm_role,\n",
    ")\n",
    "\n",
    "inputs = CreateModelInput(instance_type=\"ml.m5.xlarge\")\n",
    "\n",
    "step_model_create = CreateModelStep(name=\"CreateModelStep\", model=model, inputs=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering model to Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "# mpg_name = f\"artwork-content-{timestamp}\"\n",
    "mpg_name = \"MCH-Content-Models\"\n",
    "\n",
    "step_model_registration = RegisterModel(\n",
    "    name=\"RegisterModelStep\",\n",
    "    estimator=content_estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=mpg_name,\n",
    "    approval_status=model_approval_status,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pushing files to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_file_path='deploy.py'\n",
    "inference_file_path = 'scoring/inference.py'\n",
    "inference_prefix='inference'\n",
    "primary_prefix='code'\n",
    "\n",
    "s3_client.upload_file(Filename=f\"{deploy_file_path}\", Bucket=bucket, Key=f\"{primary_prefix}/{deploy_file_path}\")\n",
    "s3_client.upload_file(Filename=f\"{inference_file_path}\", Bucket=bucket, Key=f\"{primary_prefix}/{inference_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying models using inference script as an entry point via ProcessingStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_script_uri = f\"s3://{bucket}/{primary_prefix}/{deploy_file_path}\"\n",
    "\n",
    "# timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "endpoint_name = 'mch-artwork-content-ep-2'\n",
    "\n",
    "deployment_processor = SKLearnProcessor(\n",
    "    framework_version=\"1.0-1\",\n",
    "    role=sm_role,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    base_job_name=f\"{prefix}-deploy\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "\n",
    "step_deploy_model = ProcessingStep(\n",
    "    name=\"DeployContentModel\",\n",
    "    processor=deployment_processor,\n",
    "    inputs=[\n",
    "            ProcessingInput(source=f\"s3://{bucket}/{primary_prefix}/{inference_file_path}\",\n",
    "                                destination=\"/opt/ml/processing/input\"\n",
    "                               )\n",
    "    ],\n",
    "    job_arguments=[\n",
    "        \"--model_data\",\n",
    "        step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        \"--inference_prefix\",\n",
    "        inference_prefix,\n",
    "        \"--sm_role\",\n",
    "        sm_role,\n",
    "        \"--endpoint_name\",\n",
    "        endpoint_name\n",
    "    ],\n",
    "    code=deploy_script_uri,\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"endpoint_arn\", source=\"/opt/ml/processing/endpoint_arn\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pipeline object and passing all steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = \"artwork-content-pipeline-demo\"\n",
    "\n",
    "pipeline_steps = [step_train, step_model_registration, step_deploy_model]\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[model_approval_status],\n",
    "    steps=pipeline_steps,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:791574662255:pipeline/artwork-content-pipeline-demo',\n",
       " 'ResponseMetadata': {'RequestId': '7fade34e-0f0d-48a6-9a8f-25bdf9e6074d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '7fade34e-0f0d-48a6-9a8f-25bdf9e6074d',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '97',\n",
       "   'date': 'Thu, 09 Feb 2023 13:38:40 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=sm_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()\n",
    "execution.wait()\n",
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.lineage.visualizer import LineageTableVisualizer\n",
    "\n",
    "\n",
    "viz = LineageTableVisualizer(sagemaker_session)\n",
    "for execution_step in reversed(execution.list_steps()):\n",
    "    print(execution_step)\n",
    "    display(viz.show(pipeline_execution_step=execution_step))\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains a small sample of ovr data\n",
    "sagemaker.s3.S3Uploader.upload(\"./data/ovr_content_data_v3.csv\", \n",
    "                               f\"s3://{bucket}/{train_data_dir_prefix}\")\n",
    "#wait for file to finish uploading \n",
    "time.sleep(5)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
